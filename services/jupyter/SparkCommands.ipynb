{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b5b7438",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import requests\n",
    "import datetime\n",
    "import concurrent.futures\n",
    "import glob\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession \n",
    "import json \n",
    "\n",
    "spark = SparkSession.\\\n",
    "        builder.\\\n",
    "        appName(\"pyspark-notebook\").\\\n",
    "        master(\"spark://spark-master:7077\").\\\n",
    "        config(\"spark.executor.memory\", \"512m\").\\\n",
    "        getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51d7be08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(noise, joined_columns):\n",
    "    noise = noise\n",
    "    hashed_column = 'id'\n",
    "    start = datetime.datetime.now()\n",
    "    \n",
    "    request = requests.get(f'http://cluster-a:9200//take_data/{hashed_column}/{noise}')\n",
    "    url_content = request.content\n",
    "    csv_file = open(\"/opt/workspace/a_download.csv\", 'wb')\n",
    "    csv_file.write(url_content)\n",
    "    csv_file.close()\n",
    "\n",
    "    request = requests.get(f'http://cluster-b:9300//take_data/{hashed_column}/{noise}')\n",
    "    url_content = request.content\n",
    "    csv_file = open(\"/opt/workspace/b_download.csv\", 'wb')\n",
    "    csv_file.write(url_content)\n",
    "    csv_file.close()\n",
    "    \n",
    "    download_time = datetime.datetime.now() - start\n",
    "    \n",
    "    df_1 = spark.read.csv(path=\"/opt/workspace/a_download.csv\", sep=\",\", header=True)\n",
    "    df_2 = spark.read.csv(path=\"/opt/workspace/b_download.csv\", sep=\",\", header=True)\n",
    "\n",
    "    df_1.createOrReplaceTempView(\"a_cluster_data\")\n",
    "    df_2.createOrReplaceTempView(\"b_cluster_data\")\n",
    "\n",
    "    start = datetime.datetime.now()\n",
    "    \n",
    "    if joined_columns == 1:\n",
    "        \n",
    "        sql_result_1 = spark.sql(\"    SELECT DISTINCT a.name, a.surname\\\n",
    "                                      FROM a_cluster_data, b_cluster_data\\\n",
    "                                      JOIN a_cluster_data a ON a.name == b_cluster_data.name\\\n",
    "                                  \")\n",
    "        \n",
    "        sql_result_2 = spark.sql(\"    SELECT DISTINCT b.name, b.surname\\\n",
    "                                      FROM a_cluster_data, b_cluster_data\\\n",
    "                                      JOIN b_cluster_data b ON b.name == a_cluster_data.name\\\n",
    "                                  \")\n",
    "        \n",
    "    elif joined_columns == 2:\n",
    "\n",
    "        sql_result_1 = spark.sql(\"  SELECT DISTINCT a.name, a.surname\\\n",
    "                                    FROM a_cluster_data, b_cluster_data\\\n",
    "                                    JOIN a_cluster_data a \\\n",
    "                                    ON a.name == b_cluster_data.name and a.surname == b_cluster_data.surname\\\n",
    "                                  \")\n",
    "        \n",
    "        sql_result_2 = spark.sql(\"  SELECT DISTINCT b.name, b.surname\\\n",
    "                                    FROM a_cluster_data, b_cluster_data\\\n",
    "                                    JOIN b_cluster_data b \\\n",
    "                                    ON b.name == a_cluster_data.name and b.surname == a_cluster_data.surname\\\n",
    "                                  \")     \n",
    "        \n",
    "    sql_result_1.repartition(1).write.mode('overwrite').csv(\"/opt/workspace//a_joined_result\", header=True)\n",
    "    sql_result_2.repartition(1).write.mode('overwrite').csv(\"/opt/workspace//b_joined_result\", header=True)\n",
    "\n",
    "    joined_time = datetime.datetime.now() - start\n",
    "\n",
    "\n",
    "    URLS = ['http://cluster-a:9200//take_data/', \n",
    "            'http://cluster-b:9300//take_data/']\n",
    "    \n",
    "    def send_data(url, myfiles):\n",
    "        myfiles =  {'file': open(myfiles,'rb')}  \n",
    "        requests.post(f'{url}', files = myfiles)\n",
    "    \n",
    "    myfiles = list()\n",
    "    directoryPath= '/opt/workspace/a_joined_result/'\n",
    "    for file_name in glob.glob(directoryPath+'*.csv'):\n",
    "        myfiles.append(file_name)\n",
    "    \n",
    "    directoryPath= '/opt/workspace/b_joined_result/'\n",
    "    for file_name in glob.glob(directoryPath+'*.csv'):\n",
    "        myfiles.append(file_name)\n",
    "        \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        task = {executor.submit(send_data, url, myfile): url for url,myfile in zip(URLS, myfiles)}\n",
    "\n",
    "        for future in concurrent.futures.as_completed(task):\n",
    "            url = task[future]\n",
    "            try:\n",
    "                data = future.result()\n",
    "            except Exception as exc:\n",
    "                print('%r generated an exception: %s' % (url, exc))\n",
    "  \n",
    "\n",
    "    result = requests.get(f\"http://cluster-b:9300//return_statistics\")\n",
    "    a_cluster_result = json.loads(result.content)\n",
    "    \n",
    " \n",
    "    result = requests.get(f\"http://cluster-a:9200//return_statistics\")\n",
    "    b_cluster_result = json.loads(result.content)\n",
    "    \n",
    " \n",
    "    TP_1 = int(a_cluster_result['TP'])\n",
    "    TP_2 = int(b_cluster_result['TP'])\n",
    "    \n",
    "\n",
    "    \n",
    "    FP_1 = int(a_cluster_result['FP'])\n",
    "    FP_2 = int(a_cluster_result['FP'])\n",
    "    \n",
    "    FN_1 = int(a_cluster_result['FN'])\n",
    "    FN_2 = int(a_cluster_result['FN'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    precision = (TP_1 + TP_2) / (  TP_1 + TP_2 + FP_1 + FP_2 )\n",
    "    recall    = (TP_1 + TP_2) / (  TP_1 + TP_2 + FN_1 + FN_2 )\n",
    "    \n",
    "    return pd.DataFrame([[noise, download_time, joined_time ,precision, recall, joined_columns]], columns=['noise', 'download_time', 'joined_time', 'precision', 'recall', 'joined'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37d6b858",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(None, columns=['noise', 'download_time', 'joined_time', 'precision', 'recall', 'joined'])\n",
    "for y in range (1,3):\n",
    "    for x in range (0,300,10):\n",
    "        result = pd.concat([result, main(x,y)], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "000c8d41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result.to_csv('final_data.csv', encoding='utf-8', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f4bd90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  noise          download_time            joined_time  precision    recall  \\\n",
      "0     0 0 days 00:00:00.122239 0 days 00:00:07.453532   1.000000  1.000000   \n",
      "0    10 0 days 00:00:00.076123 0 days 00:00:07.418078   0.995280  0.010960   \n",
      "0    20 0 days 00:00:00.122202 0 days 00:00:08.492670   0.976892  0.005359   \n",
      "0    30 0 days 00:00:00.123766 0 days 00:00:09.169057   0.972618  0.003542   \n",
      "0    40 0 days 00:00:00.100297 0 days 00:00:08.414164   0.948632  0.002597   \n",
      "0    50 0 days 00:00:00.106400 0 days 00:00:13.470666   0.925081  0.002028   \n",
      "0    60 0 days 00:00:00.092818 0 days 00:00:10.562038   0.915099  0.001660   \n",
      "0    70 0 days 00:00:00.105570 0 days 00:00:12.099529   0.883505  0.001368   \n",
      "0    80 0 days 00:00:00.197422 0 days 00:00:14.597699   0.870117  0.001176   \n",
      "0    90 0 days 00:00:00.111069 0 days 00:00:11.046828   0.838207  0.001007   \n",
      "0   100 0 days 00:00:00.121358 0 days 00:00:13.440520   0.812677  0.000882   \n",
      "0   110 0 days 00:00:00.119765 0 days 00:00:18.058171   0.786569  0.000771   \n",
      "0   120 0 days 00:00:00.151918 0 days 00:00:15.069790   0.745047  0.000662   \n",
      "0   130 0 days 00:00:00.135230 0 days 00:00:15.067178   0.723413  0.000591   \n",
      "0   140 0 days 00:00:00.213181 0 days 00:00:17.074075   0.712046  0.000543   \n",
      "0   150 0 days 00:00:00.812675 0 days 00:00:17.275666   0.683962  0.000481   \n",
      "0   160 0 days 00:00:00.155485 0 days 00:00:17.279668   0.678098  0.000448   \n",
      "0   170 0 days 00:00:00.233861 0 days 00:00:20.546168   0.632967  0.000392   \n",
      "0   180 0 days 00:00:00.156695 0 days 00:00:21.018812   0.625135  0.000365   \n",
      "0   190 0 days 00:00:00.167684 0 days 00:00:22.455066   0.598205  0.000333   \n",
      "0   200 0 days 00:00:00.166710 0 days 00:00:22.587765   0.564937  0.000295   \n",
      "0   210 0 days 00:00:00.307997 0 days 00:00:23.237548   0.544918  0.000271   \n",
      "0   220 0 days 00:00:00.161337 0 days 00:00:27.528660   0.523270  0.000248   \n",
      "0   230 0 days 00:00:00.163576 0 days 00:00:26.986307   0.503460  0.000228   \n",
      "0   240 0 days 00:00:00.227805 0 days 00:00:27.753450   0.480011  0.000208   \n",
      "0   250 0 days 00:00:00.186701 0 days 00:00:29.432622   0.477979  0.000198   \n",
      "0   260 0 days 00:00:00.325939 0 days 00:00:28.308043   0.463956  0.000185   \n",
      "0   270 0 days 00:00:00.911618 0 days 00:00:31.958190   0.437701  0.000168   \n",
      "0   280 0 days 00:00:00.186372 0 days 00:00:31.179515   0.429406  0.000159   \n",
      "0   290 0 days 00:00:00.200524 0 days 00:00:35.042579   0.416667  0.000149   \n",
      "0     0 0 days 00:00:00.075349 0 days 00:00:03.083649   1.000000  1.000000   \n",
      "0    10 0 days 00:00:00.088568 0 days 00:00:02.790598   1.000000  0.010068   \n",
      "0    20 0 days 00:00:00.077629 0 days 00:00:02.348972   1.000000  0.005033   \n",
      "0    30 0 days 00:00:00.084784 0 days 00:00:04.057211   1.000000  0.003366   \n",
      "0    40 0 days 00:00:00.089614 0 days 00:00:02.680656   1.000000  0.002522   \n",
      "0    50 0 days 00:00:00.091783 0 days 00:00:03.801017   1.000000  0.002021   \n",
      "0    60 0 days 00:00:00.101223 0 days 00:00:03.923979   1.000000  0.001683   \n",
      "0    70 0 days 00:00:00.104123 0 days 00:00:04.370404   1.000000  0.001444   \n",
      "0    80 0 days 00:00:00.130580 0 days 00:00:03.866673   1.000000  0.001263   \n",
      "0    90 0 days 00:00:00.118184 0 days 00:00:04.336857   1.000000  0.001123   \n",
      "0   100 0 days 00:00:00.119810 0 days 00:00:03.743484   1.000000  0.001011   \n",
      "0   110 0 days 00:00:00.115505 0 days 00:00:05.474248   1.000000  0.000919   \n",
      "0   120 0 days 00:00:00.117185 0 days 00:00:04.394914   1.000000  0.000842   \n",
      "0   130 0 days 00:00:00.147353 0 days 00:00:05.183035   1.000000  0.000778   \n",
      "0   140 0 days 00:00:00.133824 0 days 00:00:04.460842   1.000000  0.000722   \n",
      "0   150 0 days 00:00:00.143369 0 days 00:00:05.005803   0.997512  0.000673   \n",
      "0   160 0 days 00:00:00.138140 0 days 00:00:05.501664   1.000000  0.000632   \n",
      "0   170 0 days 00:00:00.218456 0 days 00:00:06.566241   0.997509  0.000593   \n",
      "0   180 0 days 00:00:00.141702 0 days 00:00:06.246027   1.000000  0.000562   \n",
      "0   190 0 days 00:00:00.147097 0 days 00:00:06.530864   1.000000  0.000532   \n",
      "0   200 0 days 00:00:00.190019 0 days 00:00:06.908382   1.000000  0.000506   \n",
      "0   210 0 days 00:00:00.159416 0 days 00:00:08.106294   1.000000  0.000482   \n",
      "0   220 0 days 00:00:00.164897 0 days 00:00:07.559153   1.000000  0.000460   \n",
      "0   230 0 days 00:00:00.172246 0 days 00:00:06.969791   0.997509  0.000439   \n",
      "0   240 0 days 00:00:00.193837 0 days 00:00:08.026316   1.000000  0.000421   \n",
      "0   250 0 days 00:00:00.200092 0 days 00:00:08.669070   1.000000  0.000405   \n",
      "0   260 0 days 00:00:00.290118 0 days 00:00:09.259915   0.997509  0.000388   \n",
      "0   270 0 days 00:00:00.192661 0 days 00:00:10.921858   1.000000  0.000375   \n",
      "0   280 0 days 00:00:00.693084 0 days 00:00:09.662769   1.000000  0.000361   \n",
      "0   290 0 days 00:00:00.243578 0 days 00:00:10.869314   1.000000  0.000349   \n",
      "\n",
      "  joined  \n",
      "0      1  \n",
      "0      1  \n",
      "0      1  \n",
      "0      1  \n",
      "0      1  \n",
      "0      1  \n",
      "0      1  \n",
      "0      1  \n",
      "0      1  \n",
      "0      1  \n",
      "0      1  \n",
      "0      1  \n",
      "0      1  \n",
      "0      1  \n",
      "0      1  \n",
      "0      1  \n",
      "0      1  \n",
      "0      1  \n",
      "0      1  \n",
      "0      1  \n",
      "0      1  \n",
      "0      1  \n",
      "0      1  \n",
      "0      1  \n",
      "0      1  \n",
      "0      1  \n",
      "0      1  \n",
      "0      1  \n",
      "0      1  \n",
      "0      1  \n",
      "0      2  \n",
      "0      2  \n",
      "0      2  \n",
      "0      2  \n",
      "0      2  \n",
      "0      2  \n",
      "0      2  \n",
      "0      2  \n",
      "0      2  \n",
      "0      2  \n",
      "0      2  \n",
      "0      2  \n",
      "0      2  \n",
      "0      2  \n",
      "0      2  \n",
      "0      2  \n",
      "0      2  \n",
      "0      2  \n",
      "0      2  \n",
      "0      2  \n",
      "0      2  \n",
      "0      2  \n",
      "0      2  \n",
      "0      2  \n",
      "0      2  \n",
      "0      2  \n",
      "0      2  \n",
      "0      2  \n",
      "0      2  \n",
      "0      2  \n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2250d8f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
